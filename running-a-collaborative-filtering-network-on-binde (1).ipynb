{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-02T16:37:50.314963Z","iopub.execute_input":"2023-05-02T16:37:50.315345Z","iopub.status.idle":"2023-05-02T16:37:50.361920Z","shell.execute_reply.started":"2023-05-02T16:37:50.315315Z","shell.execute_reply":"2023-05-02T16:37:50.360869Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"The first step to getting your notebook working on Binder is to export the learner you have created in the main notebook. Head back to that notebook and make sure to use this line of code:\n\n**learn.export()**\n\nThe file will then show up in the Output section under /kaggle/working, below the Input section where whatever data set you are using is displayed. You can download it by right-clicking on the file.\n\nThen, follow the rest of the steps from this [Github and Binder tutorial](https://colab.research.google.com/drive/15RhBSwmTiKHritCHD2lMiS9x13mVaYS6?usp=sharing) to create a new Github repository and create your requirements.txt and upload your export.pkl file. \n\nNext, save this notebook by going to the top File menu and selecting Download Notebook. You can then upload it to Github by going to your Github account, clicking Add file and then dragging your .ipynb notebook file into Github. ","metadata":{}},{"cell_type":"code","source":"from fastai.vision.all import *\nfrom fastai.vision.widgets import *","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn_inf = load_learner('export.pkl')\n#df = pd.read_csv('item_name.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_rating(learn, user):\n    with torch.no_grad():\n        movies = torch.arange(learn.model.i_weight.num_embeddings)\n        users = tensor([user])\n        try:\n            dot = learn.u_weight(users).unsqueeze(1) * learn.i_weight(movies)\n            res = dot.sum(-1) + learn.u_bias(users) + learn.i_bias(movies).squeeze()\n            return (torch.sigmoid(res) * (learn.y_range[1]-learn.y_range[0]) + learn.y_range[0])[0]\n        except:\n            print('User not recognized') ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"itemNameText = widgets.Text(\n    value='',\n    placeholder='What is the number of the item?',\n    description='String:',\n    disabled=False   \n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"userNameText = widgets.Text(\n    value='',\n    placeholder='What user number?',\n    description='String:',\n    disabled=False   \n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lbl_pred = widgets.Label()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"btn_run = widgets.Button(description='Make Prediction')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_rating(learn, user):\n    with torch.no_grad():\n        games = torch.arange(learn.model.i_weight.num_embeddings)\n        users = tensor([user])\n        try:\n            dot = learn.u_weight(users).unsqueeze(1) * learn.i_weight(games)\n            res = dot.sum(-1) + learn.u_bias(users) + learn.i_bias(games).squeeze()\n            return (torch.sigmoid(res) * (learn.y_range[1]-learn.y_range[0]) + learn.y_range[0])[0]\n        except:\n            print('User not recognized')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def on_click_classify(change):\n    itemNum = int(itemNameText.value)\n    #itemName = itemNameText.value\n    #itemNum = list(df['0']).index(itemNameText.value)\n    userNum  = int(userNameText.value)\n    predictions = get_rating(learn_inf, userNum)\n    index = predictions.argsort(descending=True)[:20]\n    lbl_pred.value = str(predictions[itemNum].item())\n\nbtn_run.on_click(on_click_classify)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"VBox([widgets.Label('Get your predicted rating!'), \n      itemNameText, userNameText, lbl_pred, btn_run])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If you want to be able to search for item names from your original dataset, you are also going to need those names from your dataloaders object.\n\nYou can save that information to a csv file with the following lines of code:\n\n**df = pd.DataFrame(dls.classes['original_title'])** \n\n**df.to_csv('item_name.csv', index=False)**\n\nIf your item name is in a column with a different name than 'original title', replace that with your correct column label.\n\nThis will also be stored in your output directory. Download it and then upload it to your Github repository so that you can access it from your website.\n\nThen, uncomment out the lines of code above. There are two important lines in on_click_classify and one line at the top where you convert your csv file to a dataframe.","metadata":{}}]}